{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af59cd69-f548-43a8-8a48-fa401c649a78",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"C:\\Users\\prade\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:73\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_pywrap_tensorflow_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[32m     78\u001b[39m \n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mtf\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mmlflow\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\__init__.py:40\u001b[39m\n\u001b[32m     37\u001b[39m _os.environ.setdefault(\u001b[33m\"\u001b[39m\u001b[33mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:88\u001b[39m\n\u001b[32m     86\u001b[39m     sys.setdlopenflags(_default_dlopen_flags)\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     89\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback.format_exc()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     90\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFailed to load the native TensorFlow runtime.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     91\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mSee https://www.tensorflow.org/install/errors \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     92\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mfor some common causes and solutions.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     93\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mIf you need help, create an issue \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     94\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mat https://github.com/tensorflow/tensorflow/issues \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     95\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mand include the entire stack trace above this error message.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: Traceback (most recent call last):\n  File \"C:\\Users\\prade\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d6bbb9-cc92-4240-a10e-0759348165ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the wine quality dataset\n",
    "data = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv\",\n",
    "    sep=\";\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39db19b0-e5ea-45fb-8726-2d75a85c984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create train/validation/test splits\n",
    "train, test = train_test_split(data, test_size=0.25, random_state=42)\n",
    "train_x = train.drop([\"quality\"], axis=1).values\n",
    "train_y = train[[\"quality\"]].values.ravel()\n",
    "test_x = test.drop([\"quality\"], axis=1).values\n",
    "test_y = test[[\"quality\"]].values.ravel()\n",
    "\n",
    "# Further split training data for validation\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(\n",
    "    train_x, train_y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6756558a-78a1-4047-ac76-56443844cbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model signature for deployment\n",
    "signature = infer_signature(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51447fca-5ffb-4e6d-a62f-5cf0ffb2660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_train_model(learning_rate, momentum, epochs=10):\n",
    "    \"\"\"\n",
    "    Create and train a neural network with specified hyperparameters.\n",
    "\n",
    "    Returns:\n",
    "        dict: Training results including model and metrics\n",
    "    \"\"\"\n",
    "    # Normalize input features for better training stability\n",
    "    mean = np.mean(train_x, axis=0)\n",
    "    var = np.var(train_x, axis=0)\n",
    "\n",
    "    # Define model architecture\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input([train_x.shape[1]]),\n",
    "            keras.layers.Normalization(mean=mean, variance=var),\n",
    "            keras.layers.Dense(64, activation=\"relu\"),\n",
    "            keras.layers.Dropout(0.2),  # Add regularization\n",
    "            keras.layers.Dense(32, activation=\"relu\"),\n",
    "            keras.layers.Dense(1),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Compile with specified hyperparameters\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.SGD(learning_rate=learning_rate, momentum=momentum),\n",
    "        loss=\"mean_squared_error\",\n",
    "        metrics=[keras.metrics.RootMeanSquaredError()],\n",
    "    )\n",
    "\n",
    "    # Train with early stopping for efficiency\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        patience=3, restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_x,\n",
    "        train_y,\n",
    "        validation_data=(valid_x, valid_y),\n",
    "        epochs=epochs,\n",
    "        batch_size=64,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0,  # Reduce output for cleaner logs\n",
    "    )\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    val_loss, val_rmse = model.evaluate(valid_x, valid_y, verbose=0)\n",
    "\n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"val_rmse\": val_rmse,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"history\": history,\n",
    "        \"epochs_trained\": len(history.history[\"loss\"]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7603d7b0-7558-4cd8-8883-9eeb8b90256f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    \"\"\"\n",
    "    Objective function for hyperparameter optimization.\n",
    "    This function will be called by Hyperopt for each trial.\n",
    "    \"\"\"\n",
    "    with mlflow.start_run(nested=True):\n",
    "        # Log hyperparameters being tested\n",
    "        mlflow.log_params(\n",
    "            {\n",
    "                \"learning_rate\": params[\"learning_rate\"],\n",
    "                \"momentum\": params[\"momentum\"],\n",
    "                \"optimizer\": \"SGD\",\n",
    "                \"architecture\": \"64-32-1\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Train model with current hyperparameters\n",
    "        result = create_and_train_model(\n",
    "            learning_rate=params[\"learning_rate\"],\n",
    "            momentum=params[\"momentum\"],\n",
    "            epochs=15,\n",
    "        )\n",
    "\n",
    "        # Log training results\n",
    "        mlflow.log_metrics(\n",
    "            {\n",
    "                \"val_rmse\": result[\"val_rmse\"],\n",
    "                \"val_loss\": result[\"val_loss\"],\n",
    "                \"epochs_trained\": result[\"epochs_trained\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Log the trained model\n",
    "        mlflow.tensorflow.log_model(result[\"model\"], name=\"model\", signature=signature)\n",
    "\n",
    "        # Log training curves as artifacts\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        plt.figure(figsize=(12, 4))\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(result[\"history\"].history[\"loss\"], label=\"Training Loss\")\n",
    "        plt.plot(result[\"history\"].history[\"val_loss\"], label=\"Validation Loss\")\n",
    "        plt.title(\"Model Loss\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(\n",
    "            result[\"history\"].history[\"root_mean_squared_error\"], label=\"Training RMSE\"\n",
    "        )\n",
    "        plt.plot(\n",
    "            result[\"history\"].history[\"val_root_mean_squared_error\"],\n",
    "            label=\"Validation RMSE\",\n",
    "        )\n",
    "        plt.title(\"Model RMSE\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"RMSE\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"training_curves.png\")\n",
    "        mlflow.log_artifact(\"training_curves.png\")\n",
    "        plt.close()\n",
    "\n",
    "        # Return loss for Hyperopt (it minimizes)\n",
    "        return {\"loss\": result[\"val_rmse\"], \"status\": STATUS_OK}\n",
    "\n",
    "\n",
    "# Define search space for hyperparameters\n",
    "search_space = {\n",
    "    \"learning_rate\": hp.loguniform(\"learning_rate\", np.log(1e-5), np.log(1e-1)),\n",
    "    \"momentum\": hp.uniform(\"momentum\", 0.0, 0.9),\n",
    "}\n",
    "\n",
    "print(\"Search space defined:\")\n",
    "print(\"- Learning rate: 1e-5 to 1e-1 (log-uniform)\")\n",
    "print(\"- Momentum: 0.0 to 0.9 (uniform)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f861fdce-d231-4b6a-b81b-a2e8e38ffe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or set experiment\n",
    "experiment_name = \"wine-quality-optimization\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "print(f\"Starting hyperparameter optimization experiment: {experiment_name}\")\n",
    "print(\"This will run 15 trials to find optimal hyperparameters...\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"hyperparameter-sweep\"):\n",
    "    # Log experiment metadata\n",
    "    mlflow.log_params(\n",
    "        {\n",
    "            \"optimization_method\": \"Tree-structured Parzen Estimator (TPE)\",\n",
    "            \"max_evaluations\": 15,\n",
    "            \"objective_metric\": \"validation_rmse\",\n",
    "            \"dataset\": \"wine-quality\",\n",
    "            \"model_type\": \"neural_network\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Run optimization\n",
    "    trials = Trials()\n",
    "    best_params = fmin(\n",
    "        fn=objective,\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=15,\n",
    "        trials=trials,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # Find and log best results\n",
    "    best_trial = min(trials.results, key=lambda x: x[\"loss\"])\n",
    "    best_rmse = best_trial[\"loss\"]\n",
    "\n",
    "    # Log optimization results\n",
    "    mlflow.log_params(\n",
    "        {\n",
    "            \"best_learning_rate\": best_params[\"learning_rate\"],\n",
    "            \"best_momentum\": best_params[\"momentum\"],\n",
    "        }\n",
    "    )\n",
    "    mlflow.log_metrics(\n",
    "        {\n",
    "            \"best_val_rmse\": best_rmse,\n",
    "            \"total_trials\": len(trials.trials),\n",
    "            \"optimization_completed\": 1,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e636986-fb04-4470-8065-03336215ec97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584767f2-6cf0-4293-8730-7223dc505ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e86f82-8cef-4d57-aff4-b068087a4a90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7d362b-9329-4b5e-9be0-c2aa25e38758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa670cd0-8a3d-4eb7-9506-ca94741c3bed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b21afd8-85f7-4ea7-9f12-9f32c49e0992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6be3a20-53ee-43b4-ad9a-4d4a07481847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0807148-25c4-4355-9d6e-cc71c6552a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
